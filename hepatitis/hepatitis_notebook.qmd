---
title: "Hepatits C prediction"
author: "A.G."
date-modified: "last update: `r format(Sys.Date(), format = '%d %B %Y')`"
format: 
  html:
    toc: true
    toc-depth: 2
    toc-title: Contents
    toc-location: left
    df-print: paged
    standalone: true
    code-fold: true
editor: visual
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = F, warning = F, cache = T)
library(skimr)
library(tidyverse)
library(caret)
library(DMwR) # installed via archive: install.packages("/Path/to/DMwR_0.4.1.tar.gz", repos=NULL, type="source" )
library(ROCR)
```

# Intro

The aim is to predict development of hepatitis' stages.

> The target attribute for classification is Category (2): blood donors vs. Hepatitis C patients (including its progress ('just' Hepatitis C, Fibrosis, Cirrhosis).

I'll join *Cirrhosis*, *Fibrosis* and *Hepatitis C* into one category **Hepatitis**, the other one will be called **Donor**

# Read data set

```{r}
df <- read_csv("data/HepatitisCdata.csv", col_types = "dfdfdddddddddd") %>% select(-...1)

# make re-coded Category variable
# there is 0=Blood Donor and 0s=suspect Blood Donor
df$Diagnosis <- if_else(str_detect(df$Category, "Donor"), "Donor", "Hepatitis")
df$Diagnosis <- factor(df$Diagnosis, levels = c("Donor", "Hepatitis"))
df <- df %>% relocate(Diagnosis, .before = Category) %>% select(-Category)
head(df)
```

# Description

## Factor variables

```{r}
skim_desc <- skim(df)

skim_desc %>%
  yank("factor")
```

## Numeric variables

```{r}
skim_desc %>%
  yank("numeric")
```


# EDA

## Pairs plot

```{r pairs, fig.width=14, fig.height=10, warning=FALSE, message=FALSE}
GGally::ggpairs(df, aes(color = Diagnosis), 
        upper = list(continuous = GGally::wrap("cor", size = 2.0)),
        diag = list(continuous = "barDiag"),
        lower = list(continuous = GGally::wrap("points", alpha = 0.3, size=0.8))) +
  scale_color_brewer(palette = "Set1", direction = -1) +
  scale_fill_brewer(palette = "Set1", direction = -1)
```

## Age v Diagnosis

```{r}
ggplot(df, aes(Diagnosis, Age)) +
  geom_violin(aes(fill = Diagnosis), alpha = 0.5) +
  geom_jitter(alpha = 0.5, size = 0.6) +
  geom_boxplot(aes(fill = Diagnosis), alpha = 0.2) +
  scale_fill_brewer(palette = "Set1", direction = -1) +
  xlab("")
```

## Age v ALB

```{r}
ggplot(df, aes(Diagnosis, ALB)) +
  geom_violin(aes(fill = Diagnosis), alpha = 0.5) +
  geom_jitter(alpha = 0.5, size = 0.6) +
  geom_boxplot(aes(fill = Diagnosis), alpha = 0.2) +
  scale_fill_brewer(palette = "Set1", direction = -1) +
  xlab("")
```

## ALP v Diagnosis

```{r}
ggplot(df, aes(Diagnosis, ALP)) +
  geom_violin(aes(fill = Diagnosis), alpha = 0.5) +
  geom_jitter(alpha = 0.5, size = 0.6) +
  geom_boxplot(aes(fill = Diagnosis), alpha = 0.2) +
  scale_fill_brewer(palette = "Set1", direction = -1) +
  xlab("")
```

## ALT v Diagnosis

```{r}
ggplot(df, aes(Diagnosis, ALT)) +
  geom_violin(aes(fill = Diagnosis), alpha = 0.5) +
  geom_jitter(alpha = 0.5, size = 0.6) +
  geom_boxplot(aes(fill = Diagnosis), alpha = 0.2) +
  scale_fill_brewer(palette = "Set1", direction = -1) +
  coord_trans(y = "sqrt") +
  xlab("")
```

## AST v Diagnosis

```{r}
ggplot(df, aes(Diagnosis, AST)) +
  geom_violin(aes(fill = Diagnosis), alpha = 0.5) +
  geom_jitter(alpha = 0.5, size = 0.6) +
  geom_boxplot(aes(fill = Diagnosis), alpha = 0.2) +
  scale_fill_brewer(palette = "Set1", direction = -1) +
  coord_trans(y = "sqrt") +
  xlab("")
```

## BIL v Diagnosis

```{r}
ggplot(df, aes(Diagnosis, BIL)) +
  geom_violin(aes(fill = Diagnosis), alpha = 0.5) +
  geom_jitter(alpha = 0.5, size = 0.6) +
  geom_boxplot(aes(fill = Diagnosis), alpha = 0.2) +
  scale_fill_brewer(palette = "Set1", direction = -1) +
  coord_trans(y = "sqrt") +
  xlab("")
```

## CHE v Diagnosis

```{r}
ggplot(df, aes(Diagnosis, CHE)) +
  geom_violin(aes(fill = Diagnosis), alpha = 0.5) +
  geom_jitter(alpha = 0.5, size = 0.6) +
  geom_boxplot(aes(fill = Diagnosis), alpha = 0.2) +
  scale_fill_brewer(palette = "Set1", direction = -1) +
  xlab("")
```

## CHOL v Diagnosis

```{r}
ggplot(df, aes(Diagnosis, CHOL)) +
  geom_violin(aes(fill = Diagnosis), alpha = 0.5) +
  geom_jitter(alpha = 0.5, size = 0.6) +
  geom_boxplot(aes(fill = Diagnosis), alpha = 0.2) +
  scale_fill_brewer(palette = "Set1", direction = -1) +
  xlab("")
```

## CREA v Diagnosis

```{r}
ggplot(df, aes(Diagnosis, CREA)) +
  geom_violin(aes(fill = Diagnosis), alpha = 0.5) +
  geom_jitter(alpha = 0.2, size = 0.3) +
  geom_boxplot(aes(fill = Diagnosis), alpha = 0.2) +
  scale_fill_brewer(palette = "Set1", direction = -1) +
  coord_trans(y = "sqrt") +
  xlab("")
```

## GGT v Diagnosis

```{r}
ggplot(df, aes(Diagnosis, GGT)) +
  geom_violin(aes(fill = Diagnosis), alpha = 0.5) +
  geom_jitter(alpha = 0.5, size = 0.6) +
  geom_boxplot(aes(fill = Diagnosis), alpha = 0.2) +
  scale_fill_brewer(palette = "Set1", direction = -1) +
  coord_trans(y = "sqrt") +
  xlab("")
```

## Sex v Diagnosis

```{r}
sex_n <- df %>% group_by(Diagnosis, Sex) %>% summarise(N = n())

ggplot(sex_n, aes(Diagnosis, N)) +
  geom_col(aes(fill = Sex), position = "fill") +
  scale_fill_brewer(palette = "Set2", direction = -1) +
  xlab("") +
  ylab("Proportion")
```

# Data processing

## Imputation

```{r, warning=FALSE, message=FALSE}
library(mice)

imp_mice <- mice(df)
df_imp <- complete(imp_mice)

```

## Dummy vars

```{r}
to_dum <- df_imp %>% select(Sex)
# make an obj
dummies <- dummyVars(~ ., data = to_dum)
# apply it
df_dummy <- data.frame(predict(dummies, newdata = to_dum))

head(df_dummy)
```

## Scaling

```{r}
df_scaled <- df_imp %>% 
  select(-c(Sex, Diagnosis)) %>% 
  scale() %>% 
  data.frame()

head(df_scaled)
```

## Join dummies (categorical) and scaled numerical variables

```{r}
df_proc <- bind_cols(df_scaled, df_dummy)
df_proc$Diagnosis <- df$Diagnosis
head(df_proc) 
```

# Split data into training and testing

```{r data.split}
set.seed(1234)
sample_set <- createDataPartition(y = df_proc$Diagnosis, p = .75, list = FALSE)
df_train <- df_proc[sample_set,]
df_test <- df_proc[-sample_set,]
```

## Target class equalization in training data set

```{r smote}
# DMwR::SMOTE for imbalanced data: over=225 and under=150 give me 1:1 ratio
df_train_smote <- SMOTE(Diagnosis ~ ., data.frame(df_train), perc.over = 500, perc.under = 190)

df_train_smote %>% group_by(Diagnosis) %>% summarise(N=n())
```

# Random Forest

## Training

```{r rf.train}
library(doParallel)

set.seed(120)

THREADS <- 8

#cl <- makePSOCKcluster(THREADS)
#registerDoParallel(cl)


fit_ctrl <- trainControl(## 5-fold CV
                           method = "repeatedcv",
                           number = 5,
                           repeats = 10, 
                           allowParallel = T,
                           classProbs = T,
                           summaryFunction = twoClassSummary)

fit_rf <- train(Diagnosis ~ ., 
                 data = df_train_smote, 
                 metric = "ROC", 
                 method = "rf", 
                 trControl = fit_ctrl,
                 tuneGrid = expand.grid(.mtry = seq(2, 12, 0.5)),
                 ntree = 10,
                 nodesize = 1,
                 verbosity = 0,
                 verbose = FALSE)
#stopCluster(cl)

fit_rf

```

## Testing

Here's a function to summarize a model's performance, it is used below.

```{r roc.fun}
get_roc <- function(fit.obj, testing.df){
  pred_prob <- predict.train(fit.obj, newdata = testing.df, type = "prob")
  pred_roc <- prediction(predictions = pred_prob$Hepatitis, labels = testing.df$Diagnosis)
  perf_roc <- performance(pred_roc, measure = "tpr", x.measure = "fpr")
  return(list(perf_roc, pred_roc))
}
```

### ROC curve

RF's performance on the testing data set 

```{r roc.rf}
# calculate ROC
perf_pred <- get_roc(fit_rf, df_test)
perf_rf <- perf_pred[[1]]
pred_rf <- perf_pred[[2]]

# take AUC 
auc_rf <- round(unlist(slot(performance(pred_rf, measure = "auc"), "y.values")), 3)

# plot
plot(perf_rf, main = "RF ROC curve", col = "steelblue", lwd = 3)
abline(a = 0, b = 1, lwd = 3, lty = 2, col = 1)
legend(x = 0.7, y = 0.3, legend = paste0("AUC = ", auc_rf))

```

AUC is pretty close to 1.0, True Positive Rate close to 1.0 while False Positive Rate is low

### TPR v FPR

```{r tpr.rf}
# choose your cut-off
cutoff <- 0.08

# use pred_rf (pred_roc) object
plot(performance(pred_rf, measure = "tpr", x.measure = "cutoff"),
     col="steelblue", 
     ylab = "Rate", 
     xlab="Probability cutoff")

plot(performance(pred_rf, measure = "fpr", x.measure = "cutoff"), 
     add = T, col = "red")

legend(x = 0.6,y = 0.7, c("TPR (Recall)", "FPR (1-Spec)"), 
       lty = 1, col =c('steelblue', 'red'), bty = 'n', cex = 1, lwd = 2)

#abline(v = cutoff, lwd = 2, lty=6)

title("RF")
```

Unfortunately TPR falls quickly even at low probability cutoff, which means it's hard to 'catch' all cases with hepatitis without 'catching' any false positive predictions.

Let's have a look at the confusion matrix.

### Confusion matrix

With selected cutoff

```{r cm.rf}
pred_prob_rf <- predict(fit_rf, newdata = df_test, type = "prob")

# turn probabilities into classes
pred_class_rf <- ifelse(pred_prob_rf$Hepatitis > cutoff, "Hepatitis", "Donor")

pred_class_rf <- as.factor(pred_class_rf)

cm_rf <- confusionMatrix(data = pred_class_rf, 
                reference = df_test$Diagnosis,
                mode = "everything",
                positive = "Hepatitis")

cm_rf
```

We see. that almost all hepatitis cases have been predicted but we still have a lot of false positives which makes PPV quite low ~0.5

In other words, if our model predicts a patient to have hepatitis, there is ~50% chance that the patient doesn't have it.

Also, the model should be able to capture **all** cases with the disease - that's what is required in clinical practice, i.e Sensitivity/Recall should be 1.0

To overcome these two problems, a better algorithm should be used or the current one should be tuned better.

# Boosting

## Train

```{r xgb.train, eval=T}
set.seed(121)
# basic grid search
fit_xgb <- train(Diagnosis ~ ., 
                 data = df_train_smote, 
                 method = "xgbTree",
                 metric = "ROC", 
                 trControl = fit_ctrl,
                 tuneLength = 5,
                 nthreads = 12,
                 verbose = FALSE,
                 verbosity = 0)

fit_xgb$bestTune
```

## Test

### ROC

```{r roc.xgb, eval=T}
# calculate ROC
perf_pred <- get_roc(fit_xgb, df_test)
perf_xgb <- perf_pred[[1]]
pred_xgb <- perf_pred[[2]]

# take AUC 
auc_xgb <- round(unlist(slot(performance(pred_xgb, measure = "auc"), "y.values")), 3)

# plot
plot(perf_xgb, main = "XGB ROC curve", col = "steelblue", lwd = 3)
abline(a = 0, b = 1, lwd = 3, lty = 2, col = 1)
legend(x = 0.7, y = 0.3, legend = paste0("AUC = ", auc_xgb))

```

### TPR v FPR

```{r tpr.xgb, eval=T}
cutoff <- 0.12

# use pred_rf (pred_roc) object
plot(performance(pred_xgb, measure = "tpr", x.measure = "cutoff"),
     col="steelblue", 
     ylab = "Rate", 
     xlab="Probability cutoff")

plot(performance(pred_xgb, measure = "fpr", x.measure = "cutoff"), 
     add = T, col = "red")

legend(x = 0.6,y = 0.7, c("TPR (Recall)", "FPR (1-Spec)"), 
       lty = 1, col =c('steelblue', 'red'), bty = 'n', cex = 1, lwd = 2)

abline(v = cutoff, lwd = 2, lty=6)

title("XGB")
```

### Confusion matrix with selected cutoff

```{r cm.xgb, eval=T}
pred_prob_xgb <- predict(fit_xgb, newdata = df_test, type = "prob")

# turn probabilities into classes
pred_class_xgb <- ifelse(pred_prob_xgb$Hepatitis > cutoff, "Hepatitis", "Donor")

pred_class_xgb <- as.factor(pred_class_xgb)

cm_xgb <- confusionMatrix(data = pred_class_xgb, 
                reference = df_test$Diagnosis,
                mode = "everything",
                positive = "Hepatitis")

cm_xgb
```
