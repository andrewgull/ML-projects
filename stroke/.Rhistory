verbosity = 0,
verbose = FALSE)
set.seed(122)
fit_nb <- train(stroke ~ .,
data = df_train_smote,
metric = "Kappa",
method = "nbDiscrete",
trControl = fit_ctrl_kp,
#tuneGrid = expand.grid(.nIter = seq(5, 15, 1)),
verbosity = 0,
verbose = FALSE)
df_train_smote
sum(is.na(df_train_smote))
apply(df_train_smote, 2, is.na)
apply(df_train_smote, 2, sum(is.na))
apply(df_train_smote, 2, sum(is.na()))
apply(df_train_smote, 2, sum(is.na(x)))
apply(df_train_smote, 2, function(x){sum(is.na(x))})
apply(df_test, 2, function(x){sum(is.na(x))})
set.seed(122)
fit_nb <- train(stroke ~ .,
data = df_train_smote,
metric = "Kappa",
method = "awnb",
trControl = fit_ctrl_kp,
#tuneGrid = expand.grid(.nIter = seq(5, 15, 1)),
verbosity = 0,
verbose = FALSE)
head(df_train_smote)
is.factor(df_train_smote$stroke)
set.seed(122)
fit_nb <- train(stroke ~ .,
data = df_train_smote,
metric = "Kappa",
method = "nbSearch",
trControl = fit_ctrl_kp,
#tuneGrid = expand.grid(.nIter = seq(5, 15, 1)),
verbosity = 0,
verbose = FALSE)
install.packages("fastAdaboost")
install.packages("adabag")
set.seed(122)
fit_adb <- train(stroke ~ .,
data = df_train_smote,
metric = "Kappa",
method = "AdaBoost.M1",
trControl = fit_ctrl_kp,
#tuneGrid = expand.grid(.nIter = seq(5, 15, 1)),
verbosity = 0,
verbose = FALSE)
set.seed(122)
cl <- makePSOCKcluster(14)
library(doParallel)
set.seed(122)
cl <- makePSOCKcluster(10)
registerDoParallel(cl)
fit_adb <- train(stroke ~ .,
data = df_train_smote,
metric = "Kappa",
method = "AdaBoost.M1",
trControl = fit_ctrl_kp,
#tuneGrid = expand.grid(.nIter = seq(5, 15, 1)),
verbosity = 0,
verbose = FALSE)
stopCluster(cl)
fit_adb
pred_prob_adb <- predict(fit_adb, newdata=df_test, type = "prob")
# choose your cut-off
cutoff = 0.5
# turn probabilities into classes
pred_class_adb <- ifelse(pred_prob_adb$yes > cutoff, "yes", "no")
pred_class_adb <- as.factor(pred_class_adb)
cm_adb <- confusionMatrix(data = pred_class_adb,
reference = df_test$stroke,
mode="everything",
positive="yes")
cm_adb
# calculate ROC
peadb_pred <- get_roc(fit_adb, df_test)
peadb_adb <- peadb_pred[[1]]
pred_adb <- peadb_pred[[2]]
# take AUC
auc_adb <- round(unlist(slot(peadbormance(pred_adb, measure = "auc"), "y.values")), 3)
# calculate ROC
perf_pred <- get_roc(fit_adb, df_test)
perf_adb <- perf_pred[[1]]
pred_adb <- perf_pred[[2]]
# take AUC
auc_adb <- round(unlist(slot(performance(pred_adb, measure = "auc"), "y.values")), 3)
# plot
plot(perf_adb, main = "RF-k ROC curve", col = "steelblue", lwd = 3)
abline(a = 0, b = 1, lwd = 3, lty = 2, col = 1)
legend(x = 0.7, y = 0.3, legend = paste0("AUC = ", auc_adb))
# use pred_rf (pred_roc) object
plot(performance(pred_adb, measure = "tpr", x.measure = "cutoff"),
col="steelblue",
ylab = "Rate",
xlab="Probability cutoff")
plot(performance(pred_adb, measure = "fpr", x.measure = "cutoff"),
add = T, col = "red")
legend(x = 0.6,y = 0.7, c("TPR (Recall)", "FPR (1-Spec)"),
lty = 1, col =c('steelblue', 'red'), bty = 'n', cex = 1, lwd = 2)
abline(v= 0.07, lwd = 2, lty=6)
title("AdaBoost.M1")
# use pred_rf (pred_roc) object
plot(performance(pred_adb, measure = "tpr", x.measure = "cutoff"),
col="steelblue",
ylab = "Rate",
xlab="Probability cutoff")
plot(performance(pred_adb, measure = "fpr", x.measure = "cutoff"),
add = T, col = "red")
legend(x = 0.6,y = 0.7, c("TPR (Recall)", "FPR (1-Spec)"),
lty = 1, col =c('steelblue', 'red'), bty = 'n', cex = 1, lwd = 2)
abline(v= 0.37, lwd = 2, lty=6)
title("AdaBoost.M1")
# use pred_rf (pred_roc) object
plot(performance(pred_adb, measure = "tpr", x.measure = "cutoff"),
col="steelblue",
ylab = "Rate",
xlab="Probability cutoff")
plot(performance(pred_adb, measure = "fpr", x.measure = "cutoff"),
add = T, col = "red")
legend(x = 0.6,y = 0.7, c("TPR (Recall)", "FPR (1-Spec)"),
lty = 1, col =c('steelblue', 'red'), bty = 'n', cex = 1, lwd = 2)
abline(v= 0.35, lwd = 2, lty=6)
title("AdaBoost.M1")
# use pred_rf (pred_roc) object
plot(performance(pred_adb, measure = "tpr", x.measure = "cutoff"),
col="steelblue",
ylab = "Rate",
xlab="Probability cutoff")
plot(performance(pred_adb, measure = "fpr", x.measure = "cutoff"),
add = T, col = "red")
legend(x = 0.6,y = 0.7, c("TPR (Recall)", "FPR (1-Spec)"),
lty = 1, col =c('steelblue', 'red'), bty = 'n', cex = 1, lwd = 2)
abline(v= 0.34, lwd = 2, lty=6)
title("AdaBoost.M1")
# use pred_rf (pred_roc) object
plot(performance(pred_adb, measure = "tpr", x.measure = "cutoff"),
col="steelblue",
ylab = "Rate",
xlab="Probability cutoff")
plot(performance(pred_adb, measure = "fpr", x.measure = "cutoff"),
add = T, col = "red")
legend(x = 0.6,y = 0.7, c("TPR (Recall)", "FPR (1-Spec)"),
lty = 1, col =c('steelblue', 'red'), bty = 'n', cex = 1, lwd = 2)
abline(v= 0.345, lwd = 2, lty=6)
title("AdaBoost.M1")
# use pred_rf (pred_roc) object
plot(performance(pred_adb, measure = "tpr", x.measure = "cutoff"),
col="steelblue",
ylab = "Rate",
xlab="Probability cutoff")
plot(performance(pred_adb, measure = "fpr", x.measure = "cutoff"),
add = T, col = "red")
legend(x = 0.6,y = 0.7, c("TPR (Recall)", "FPR (1-Spec)"),
lty = 1, col =c('steelblue', 'red'), bty = 'n', cex = 1, lwd = 2)
abline(v= 0.3455, lwd = 2, lty=6)
title("AdaBoost.M1")
# use pred_rf (pred_roc) object
plot(performance(pred_adb, measure = "tpr", x.measure = "cutoff"),
col="steelblue",
ylab = "Rate",
xlab="Probability cutoff")
plot(performance(pred_adb, measure = "fpr", x.measure = "cutoff"),
add = T, col = "red")
legend(x = 0.6,y = 0.7, c("TPR (Recall)", "FPR (1-Spec)"),
lty = 1, col =c('steelblue', 'red'), bty = 'n', cex = 1, lwd = 2)
abline(v= 0.347, lwd = 2, lty=6)
title("AdaBoost.M1")
pred_prob_adb <- predict(fit_adb, newdata=df_test, type = "prob")
# choose your cut-off
cutoff = 0.347
# turn probabilities into classes
pred_class_adb <- ifelse(pred_prob_adb$yes > cutoff, "yes", "no")
pred_class_adb <- as.factor(pred_class_adb)
cm_adb <- confusionMatrix(data = pred_class_adb,
reference = df_test$stroke,
mode="everything",
positive="yes")
cm_adb
# predict probabilities
pred_prob_rf <- predict(fit_rf, newdata=df_test, type = "prob")
# choose your cut-off
cutoff = 0.01
# turn probabilities into classes
pred_class_rf <- ifelse(pred_prob_rf$yes > cutoff, "yes", "no")
pred_class_rf <- as.factor(pred_class_rf)
cm_rf <- confusionMatrix(data = pred_class_rf,
reference = df_test$stroke,
mode="everything",
positive="yes")
cm_rf
# use pred_rf (pred_roc) object
plot(performance(pred_rf, measure = "tpr", x.measure = "cutoff"),
col="steelblue",
ylab = "Rate",
xlab="Probability cutoff")
plot(performance(pred_rf, measure = "fpr", x.measure = "cutoff"),
add = T, col = "red")
legend(x = 0.6,y = 0.7, c("TPR (Recall)", "FPR (1-Spec)"),
lty = 1, col =c('steelblue', 'red'), bty = 'n', cex = 1, lwd = 2)
abline(v= 0.07, lwd = 2, lty=6)
title("RF-k")
# use pred_rf (pred_roc) object
plot(performance(pred_rf, measure = "tpr", x.measure = "cutoff"),
col="steelblue",
ylab = "Rate",
xlab="Probability cutoff")
plot(performance(pred_rf, measure = "fpr", x.measure = "cutoff"),
add = T, col = "red")
legend(x = 0.6,y = 0.7, c("TPR (Recall)", "FPR (1-Spec)"),
lty = 1, col =c('steelblue', 'red'), bty = 'n', cex = 1, lwd = 2)
abline(v= 0.01, lwd = 2, lty=6)
title("RF-k")
# use pred_rf (pred_roc) object
plot(performance(pred_rf, measure = "tpr", x.measure = "cutoff"),
col="steelblue",
ylab = "Rate",
xlab="Probability cutoff")
plot(performance(pred_rf, measure = "fpr", x.measure = "cutoff"),
add = T, col = "red")
legend(x = 0.6,y = 0.7, c("TPR (Recall)", "FPR (1-Spec)"),
lty = 1, col =c('steelblue', 'red'), bty = 'n', cex = 1, lwd = 2)
abline(v= 0.02, lwd = 2, lty=6)
title("RF-k")
# use pred_rf (pred_roc) object
plot(performance(pred_rf_roc, measure = "tpr", x.measure = "cutoff"),
col="steelblue",
ylab = "Rate",
xlab="Probability cutoff")
plot(performance(pred_rf_roc, measure = "fpr", x.measure = "cutoff"),
add = T, col = "red")
legend(x = 0.6,y = 0.7, c("TPR (Recall)", "FPR (1-Spec)"),
lty = 1, col =c('steelblue', 'red'), bty = 'n', cex = 1, lwd = 2)
abline(v= 0.02, lwd = 2, lty=6)
title("RF-r")
# predict probabilities
pred_prob_rf <- predict(fit_rf, newdata=df_test, type = "prob")
# choose your cut-off
cutoff = 0.02
# turn probabilities into classes
pred_class_rf <- ifelse(pred_prob_rf$yes > cutoff, "yes", "no")
pred_class_rf <- as.factor(pred_class_rf)
cm_rf <- confusionMatrix(data = pred_class_rf,
reference = df_test$stroke,
mode="everything",
positive="yes")
cm_rf
# predict probabilities
pred_prob_rf <- predict(fit_rf, newdata=df_test, type = "prob")
# choose your cut-off
cutoff = 0.016
# turn probabilities into classes
pred_class_rf <- ifelse(pred_prob_rf$yes > cutoff, "yes", "no")
pred_class_rf <- as.factor(pred_class_rf)
cm_rf <- confusionMatrix(data = pred_class_rf,
reference = df_test$stroke,
mode="everything",
positive="yes")
cm_rf
set.seed(122)
cl <- makePSOCKcluster(10)
registerDoParallel(cl)
fit_adb <- train(stroke ~ .,
data = df_train_smote,
metric = "Kappa",
method = "AdaBoost.M1",
trControl = fit_ctrl_kp,
tuneGrid = expand.grid(.maxdepth = seq(1, 5, 1), .mfinal = seq(50, 150, 50), .coeflearn = c("Freund")),
verbosity = 0,
verbose = FALSE)
# coeflearn=Freund was chosen by automatic grid search, mfinal choice comes from there too
stopCluster(cl)
fit_adb
# calculate ROC
perf_pred <- get_roc(fit_adb, df_test)
perf_adb <- perf_pred[[1]]
pred_adb <- perf_pred[[2]]
# take AUC
auc_adb <- round(unlist(slot(performance(pred_adb, measure = "auc"), "y.values")), 3)
# plot
plot(perf_adb, main = "RF-k ROC curve", col = "steelblue", lwd = 3)
abline(a = 0, b = 1, lwd = 3, lty = 2, col = 1)
legend(x = 0.7, y = 0.3, legend = paste0("AUC = ", auc_adb))
set.seed(122)
cl <- makePSOCKcluster(10)
registerDoParallel(cl)
fit_adb <- train(stroke ~ .,
data = df_train_smote,
metric = "Kappa",
method = "AdaBoost.M1",
trControl = fit_ctrl_kp,
tuneGrid = expand.grid(.maxdepth = seq(1, 7, 1), .mfinal = seq(100, 200, 50), .coeflearn = c("Freund")),
verbosity = 0,
verbose = FALSE)
# coeflearn=Freund was chosen by automatic grid search, mfinal choice comes from there too
stopCluster(cl)
fit_adb
# calculate ROC
perf_pred <- get_roc(fit_adb, df_test)
perf_adb <- perf_pred[[1]]
pred_adb <- perf_pred[[2]]
# take AUC
auc_adb <- round(unlist(slot(performance(pred_adb, measure = "auc"), "y.values")), 3)
# plot
plot(perf_adb, main = "RF-k ROC curve", col = "steelblue", lwd = 3)
abline(a = 0, b = 1, lwd = 3, lty = 2, col = 1)
legend(x = 0.7, y = 0.3, legend = paste0("AUC = ", auc_adb))
# use pred_rf (pred_roc) object
plot(performance(pred_adb, measure = "tpr", x.measure = "cutoff"),
col="steelblue",
ylab = "Rate",
xlab="Probability cutoff")
plot(performance(pred_adb, measure = "fpr", x.measure = "cutoff"),
add = T, col = "red")
legend(x = 0.6,y = 0.7, c("TPR (Recall)", "FPR (1-Spec)"),
lty = 1, col =c('steelblue', 'red'), bty = 'n', cex = 1, lwd = 2)
abline(v= 0.347, lwd = 2, lty=6)
title("AdaBoost.M1")
set.seed(122)
cl <- makePSOCKcluster(18)
registerDoParallel(cl)
fit_adb <- train(stroke ~ .,
data = df_train_smote,
metric = "Kappa",
method = "AdaBoost.M1",
trControl = fit_ctrl_kp,
tuneGrid = expand.grid(.maxdepth = seq(1, 10, 1), .mfinal = seq(100, 150, 50), .coeflearn = c("Freund")),
verbosity = 0,
verbose = FALSE)
# coeflearn=Freund was chosen by automatic grid search, mfinal choice comes from there too
stopCluster(cl)
fit_adb
# calculate ROC
perf_pred <- get_roc(fit_adb, df_test)
perf_adb <- perf_pred[[1]]
pred_adb <- perf_pred[[2]]
# take AUC
auc_adb <- round(unlist(slot(performance(pred_adb, measure = "auc"), "y.values")), 3)
# plot
plot(perf_adb, main = "RF-k ROC curve", col = "steelblue", lwd = 3)
abline(a = 0, b = 1, lwd = 3, lty = 2, col = 1)
legend(x = 0.7, y = 0.3, legend = paste0("AUC = ", auc_adb))
# use pred_rf (pred_roc) object
plot(performance(pred_adb, measure = "tpr", x.measure = "cutoff"),
col="steelblue",
ylab = "Rate",
xlab="Probability cutoff")
plot(performance(pred_adb, measure = "fpr", x.measure = "cutoff"),
add = T, col = "red")
legend(x = 0.6,y = 0.7, c("TPR (Recall)", "FPR (1-Spec)"),
lty = 1, col =c('steelblue', 'red'), bty = 'n', cex = 1, lwd = 2)
abline(v= 0.347, lwd = 2, lty=6)
title("AdaBoost.M1")
# use pred_rf (pred_roc) object
plot(performance(pred_adb, measure = "tpr", x.measure = "cutoff"),
col="steelblue",
ylab = "Rate",
xlab="Probability cutoff")
plot(performance(pred_adb, measure = "fpr", x.measure = "cutoff"),
add = T, col = "red")
legend(x = 0.6,y = 0.7, c("TPR (Recall)", "FPR (1-Spec)"),
lty = 1, col =c('steelblue', 'red'), bty = 'n', cex = 1, lwd = 2)
abline(v= 0.18, lwd = 2, lty=6)
title("AdaBoost.M1")
# use pred_rf (pred_roc) object
plot(performance(pred_adb, measure = "tpr", x.measure = "cutoff"),
col="steelblue",
ylab = "Rate",
xlab="Probability cutoff")
plot(performance(pred_adb, measure = "fpr", x.measure = "cutoff"),
add = T, col = "red")
legend(x = 0.6,y = 0.7, c("TPR (Recall)", "FPR (1-Spec)"),
lty = 1, col =c('steelblue', 'red'), bty = 'n', cex = 1, lwd = 2)
abline(v= 0.16, lwd = 2, lty=6)
title("AdaBoost.M1")
pred_prob_adb <- predict(fit_adb, newdata=df_test, type = "prob")
# choose your cut-off
cutoff = 0.16
# turn probabilities into classes
pred_class_adb <- ifelse(pred_prob_adb$yes > cutoff, "yes", "no")
pred_class_adb <- as.factor(pred_class_adb)
cm_adb <- confusionMatrix(data = pred_class_adb,
reference = df_test$stroke,
mode="everything",
positive="yes")
cm_adb
# calculate ROC
perf_pred <- get_roc(fit_adb, df_test)
perf_adb <- perf_pred[[1]]
pred_adb <- perf_pred[[2]]
# take AUC
auc_adb <- round(unlist(slot(performance(pred_adb, measure = "auc"), "y.values")), 3)
# plot
plot(perf_adb, main = "AdaBoost ROC curve", col = "steelblue", lwd = 3)
abline(a = 0, b = 1, lwd = 3, lty = 2, col = 1)
legend(x = 0.7, y = 0.3, legend = paste0("AUC = ", auc_adb))
# calculate ROC
perf_pred_adb <- get_roc(fit_adb, df_test)
perf_adb <- perf_pred_adb[[1]]
pred_adb <- perf_pred_adb[[2]]
# take AUC
auc_adb <- round(unlist(slot(performance(pred_adb, measure = "auc"), "y.values")), 3)
# plot
plot(perf_adb, main = "AdaBoost ROC curve", col = "steelblue", lwd = 3)
abline(a = 0, b = 1, lwd = 3, lty = 2, col = 1)
legend(x = 0.7, y = 0.3, legend = paste0("AUC = ", auc_adb))
fit_ctrl_kp10 <- trainControl(## 10-fold CV
method = "repeatedcv",
number = 10,
repeats = 10,
allowParallel = T)
set.seed(122)
cl <- makePSOCKcluster(18)
registerDoParallel(cl)
fit_adb <- train(stroke ~ .,
data = df_train_smote,
metric = "Kappa",
method = "AdaBoost.M1",
trControl = fit_ctrl_kp10,
tuneGrid = expand.grid(.maxdepth = seq(1, 10, 1), .mfinal = seq(100, 150, 50), .coeflearn = c("Freund")),
verbosity = 0,
verbose = FALSE)
stopCluster(cl)
fit_adb
load("~/Projects/ML-projects/stroke/data/workspace.RData")
knitr::opts_chunk$set(echo = TRUE, message = F, warning = F, cache = F)
library(tidyverse)
library(caret)
#library(GGally)
library(DMwR) # installed via archive: install.packages("/Path/to/DMwR_0.4.1.tar.gz", repos=NULL, type="source" )
library(ROCR)
THREADS <- 10
# predict probabilities
pred_prob_rf_roc <- predict(fit_rf_roc, newdata = df_test, type = "prob")
# choose your cut-off
cutoff = 0.01
# turn probabilities into classes
pred_class_rf_roc <- ifelse(pred_prob_rf_roc$yes > cutoff, "yes", "no")
pred_class_rf_roc <- as.factor(pred_class_rf_roc)
cm_rf <- confusionMatrix(data = pred_class_rf_roc,
reference = df_test$stroke,
mode = "everything",
positive = "yes")
cm_rf
# predict probabilities
pred_prob_rf <- predict(fit_rf, newdata=df_test, type = "prob")
# choose your cut-off
cutoff = 0.01
# turn probabilities into classes
pred_class_rf <- ifelse(pred_prob_rf$yes > cutoff, "yes", "no")
pred_class_rf <- as.factor(pred_class_rf)
cm_rf <- confusionMatrix(data = pred_class_rf,
reference = df_test$stroke,
mode = "everything",
positive = "yes")
cm_rf
# use pred_rf (pred_roc) object
plot(performance(pred_rf_roc, measure = "tpr", x.measure = "cutoff"),
col = "steelblue",
ylab = "Rate",
xlab = "Probability cutoff")
plot(performance(pred_rf_roc, measure = "fpr", x.measure = "cutoff"),
add = T, col = "red")
legend(x = 0.6,y = 0.7, c("TPR (Recall)", "FPR (1-Spec)"),
lty = 1, col = c('steelblue', 'red'), bty = 'n', cex = 1, lwd = 2)
abline(v = 0.02, lwd = 2, lty=6)
title("RF-r")
# use pred_rf (pred_roc) object
plot(performance(pred_rf, measure = "tpr", x.measure = "cutoff"),
col="steelblue",
ylab = "Rate",
xlab="Probability cutoff")
plot(performance(pred_rf, measure = "fpr", x.measure = "cutoff"),
add = T, col = "red")
legend(x = 0.6,y = 0.7, c("TPR (Recall)", "FPR (1-Spec)"),
lty = 1, col =c('steelblue', 'red'), bty = 'n', cex = 1, lwd = 2)
abline(v = 0.02, lwd = 2, lty=6)
title("RF-k")
# calculate ROC
perf_pred_roc <- get_roc(fit_rf_roc, df_test)
perf_rf_roc <- perf_pred_roc[[1]]
pred_rf_roc <- perf_pred_roc[[2]]
# take AUC
auc_rf_roc <- round(unlist(slot(performance(pred_rf_roc, measure = "auc"), "y.values")), 3)
# plot
plot(perf_rf_roc, main = "RF-r ROC curve", col = "steelblue", lwd = 3)
abline(a = 0, b = 1, lwd = 3, lty = 2, col = 1)
legend(x = 0.7, y = 0.3, legend = paste0("AUC = ", auc_rf_roc))
# calculate ROC
perf_pred <- get_roc(fit_rf, df_test)
perf_rf <- perf_pred[[1]]
pred_rf <- perf_pred[[2]]
# take AUC
auc_rf <- round(unlist(slot(performance(pred_rf, measure = "auc"), "y.values")), 3)
# plot
plot(perf_rf, main = "RF-k ROC curve", col = "steelblue", lwd = 3)
abline(a = 0, b = 1, lwd = 3, lty = 2, col = 1)
legend(x = 0.7, y = 0.3, legend = paste0("AUC = ", auc_rf))
# predict probabilities
pred_prob_rf_roc <- predict(fit_rf_roc, newdata = df_test, type = "prob")
# choose your cut-off
cutoff = 0.01
# turn probabilities into classes
pred_class_rf_roc <- ifelse(pred_prob_rf_roc$yes > cutoff, "yes", "no")
pred_class_rf_roc <- as.factor(pred_class_rf_roc)
cm_rf <- confusionMatrix(data = pred_class_rf_roc,
reference = df_test$stroke,
mode = "everything",
positive = "yes")
cm_rf
