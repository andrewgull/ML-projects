# calculate ROC
perf_pred <- get_roc(fit_xgb_roc, df_test)
perf_roc_xgb <- perf_pred[[1]]
pred_roc_xgb <- perf_pred[[2]]
# take AUC
auc_xgb <- round(unlist(slot(performance(pred_roc_xgb, measure = "auc"), "y.values")), 3)
# plot
plot(perf_roc_xgb, main = "XGB ROC curve", col = "steelblue", lwd = 3)
abline(a = 0, b = 1, lwd = 3, lty = 2, col = 1)
legend(x = 0.7, y = 0.3, legend = paste0("AUC = ", auc_xgb))
knitr::opts_chunk$set(echo = TRUE, message = F, warning = F, cache = F)
library(tidyverse)
library(caret)
#library(GGally)
library(DMwR) # installed via archive: install.packages("/Path/to/DMwR_0.4.1.tar.gz", repos=NULL, type="source" )
library(ROCR)
library(doParallel)
cl <- makePSOCKcluster(18)
registerDoParallel(cl)
set.seed(123)
fit_rf_roc <- train(stroke ~ .,
data = df_train_smote,
metric = "Sensitivity",
method = "rf",
trControl = fit_ctrl_xgb_roc,
tuneGrid = expand.grid(.mtry = seq(3, 6, 0.5)), # I've tried all values greater than these
verbosity = 0,
verbose = FALSE)
stopCluster(cl)
knitr::opts_chunk$set(echo = TRUE, message = F, warning = F, cache = F)
library(tidyverse)
library(caret)
#library(GGally)
library(DMwR) # installed via archive: install.packages("/Path/to/DMwR_0.4.1.tar.gz", repos=NULL, type="source" )
library(ROCR)
df <- read_csv("data/healthcare-dataset-stroke-data.csv", col_types = "cfdfffffddcf", na = c("Unknown", "N/A"))
# if you set smoking_status to factor in col_types, na() won't work
df$smoking_status <- as_factor(df$smoking_status)
df$smoking_status <- fct_relevel(df$smoking_status, c("never smoked", "formerly smoked", "smokes"))
df$stroke <- factor(ifelse(df$stroke == 1, "yes", "no"), levels = c("no", "yes"))
df
df$id <- NULL
skimr::skim_to_wide(df)
df %>% group_by(stroke, smoking_status) %>% summarise(N=n())
df %>% filter(is.na(bmi)) %>% group_by(stroke) %>% summarise(N=n())
df <- df %>% filter(gender != "Other")
ggplot(df, aes(stroke, age)) +
geom_boxplot(aes(fill = stroke), alpha = 0.5, varwidth = T, notch = T) +
geom_violin(aes(fill = stroke), alpha = 0.5) +
scale_fill_brewer(palette = "Set1", direction = -1) +
xlab("")
ggplot(df, aes(stroke, age)) +
geom_violin(alpha=0.3) +
geom_jitter(alpha=0.2, size=0.8, width = 0.15, height = 0.1, aes(color = gender)) +
geom_boxplot(alpha = 0.2) +
scale_color_brewer(palette = "Set2", direction = -1)
ggplot(df, aes(stroke, bmi)) +
geom_boxplot(aes(fill = stroke), alpha = 0.5, varwidth = T, notch = T) +
geom_violin(aes(fill = stroke), alpha = 0.5) +
scale_fill_brewer(palette = "Set1", direction = -1) +
xlab("")
gender <- df %>% group_by(stroke, gender) %>% summarize(N=n())
ggplot(gender, aes(stroke, N)) +
geom_bar(aes(fill=gender), alpha = 0.8, stat = "identity", position = "fill")+
scale_fill_brewer(palette = "Set2", direction = -1)+
ylab("proportion")
hyptens <- df %>% group_by(stroke, hypertension) %>% summarize(N=n())
hyptens
ggplot(hyptens, aes(stroke, N)) +
geom_bar(aes(fill=hypertension), alpha = 0.8, stat = "identity", position = "fill")+
scale_fill_brewer(palette = "Set2", direction = -1)+
ylab("proportion")
ggplot(df, aes(stroke, avg_glucose_level)) +
geom_boxplot(aes(fill = stroke), alpha = 0.5, varwidth = T, notch = T) +
geom_violin(aes(fill = stroke), alpha = 0.5) +
scale_fill_brewer(palette = "Set1", direction = -1) +
xlab("")
df_scaled <- df %>% select(avg_glucose_level, age, bmi) %>% scale() %>% data.frame()
# select vars
to_dum <- df %>% select(gender, ever_married, work_type, Residence_type)
# make an obj
dummies <- dummyVars(~ ., data=to_dum)
# apply it
df_dummy <- data.frame(predict(dummies, newdata=to_dum))
head(df_dummy)
df_proc <- bind_cols(df_scaled, df_dummy, select(df, hypertension, heart_disease, stroke))
head(df_proc)
df_proc <- df_proc %>%
mutate(bmi = ifelse(is.na(bmi), median(bmi, na.rm = TRUE), bmi))
fit_ctrl_xgb_roc <- trainControl(## 10-fold CV
method = "repeatedcv",
number = 5,
repeats = 10,
allowParallel = T,
classProbs = T,
summaryFunction = twoClassSummary)
fit_ctrl_xgb_kappa <- trainControl(## 10-fold CV
method = "repeatedcv",
number = 5,
repeats = 10,
allowParallel = T)
set.seed(1234)
sample_set <- createDataPartition(y = df_proc$stroke, p = .75, list = FALSE)
df_train <- df_proc[sample_set,]
df_test <- df_proc[-sample_set,]
# DMwR::SMOTE for imbalanced data: over=225 and under=150 give me 1:1 ratio
df_train_smote <- SMOTE(stroke ~ ., data.frame(df_train), perc.over = 225, perc.under = 150)
df_train_smote %>% group_by(stroke) %>% summarise(N=n())
library(doParallel)
cl <- makePSOCKcluster(18)
registerDoParallel(cl)
set.seed(123)
fit_rf_roc <- train(stroke ~ .,
data = df_train_smote,
metric = "Sensitivity",
method = "rf",
trControl = fit_ctrl_xgb_roc,
tuneGrid = expand.grid(.mtry = seq(3, 6, 0.5)), # I've tried all values greater than these
verbosity = 0,
verbose = FALSE)
fit_rf_roc
stopCluster(cl)
predClasses_rf_roc <- predict(fit_rf_roc, newdata=df_test)
cm_rf_roc <- confusionMatrix(data = predClasses_rf_roc,
reference = df_test$stroke,
mode="everything",
positive="yes")
cm_rf_roc
fit_ctrl_xgb_roc <- trainControl(## 10-fold CV
method = "repeatedcv",
number = 5,
repeats = 10,
allowParallel = T,
classProbs = T,
summaryFunction = twoClassSummary)
fit_ctrl_xgb_sens <- trainControl(## 10-fold CV
method = "repeatedcv",
number = 5,
repeats = 10,
allowParallel = T)
library(doParallel)
cl <- makePSOCKcluster(18)
registerDoParallel(cl)
set.seed(123)
fit_rf_roc <- train(stroke ~ .,
data = df_train_smote,
metric = "Sensitivity",
method = "rf",
trControl = fit_ctrl_xgb_sens,
tuneGrid = expand.grid(.mtry = seq(3, 6, 0.5)), # I've tried all values greater than these
verbosity = 0,
verbose = FALSE)
stopCluster(cl)
fit_rf_roc
predClasses_rf <- predict(fit_rf, newdata=df_test)
fit_ctrl_roc <- trainControl(## 10-fold CV
method = "repeatedcv",
number = 5,
repeats = 10,
allowParallel = T,
classProbs = T,
summaryFunction = twoClassSummary)
fit_ctrl_sens <- trainControl(## 10-fold CV
method = "repeatedcv",
number = 5,
repeats = 10,
allowParallel = T)
library(doParallel)
cl <- makePSOCKcluster(18)
registerDoParallel(cl)
set.seed(123)
fit_rf <- train(stroke ~ .,
data = df_train_smote,
metric = "Sensitivity",
method = "rf",
trControl = fit_ctrl_sens,
tuneGrid = expand.grid(.mtry = seq(3, 6, 0.5)), # I've tried all values greater than these
verbosity = 0,
verbose = FALSE)
stopCluster(cl)
fit_rf
imp_vars_rf <- varImp(fit_rf)
plot(imp_vars_rf, main="Variable Importance with RF")
predClasses_rf <- predict(fit_rf, newdata=df_test)
cm_rf <- confusionMatrix(data = predClasses_rf,
reference = df_test$stroke,
mode="everything",
positive="yes")
cm_rf
# calculate ROC
perf_pred <- get_roc(fit_rf, df_test)
get_roc <- function(fit.obj, testing.df){
pred_prob <- predict.train(fit.obj, newdata = testing.df, type="prob")
pred_roc <- prediction(predictions = pred_prob$yes, labels = testing.df$stroke)
perf_roc <- performance(pred_roc, measure="tpr", x.measure = "fpr")
return(list(perf_roc, pred_roc))
}
# calculate ROC
perf_pred <- get_roc(fit_rf, df_test)
perf_rf <- perf_pred[[1]]
pred_rf <- perf_pred[[2]]
# take AUC
auc_rf <- round(unlist(slot(performance(pred_rf, measure = "auc"), "y.values")), 3)
# plot
plot(perf_rf, main = "RF ROC curve", col = "steelblue", lwd = 3)
abline(a = 0, b = 1, lwd = 3, lty = 2, col = 1)
legend(x = 0.7, y = 0.3, legend = paste0("AUC = ", auc_rf))
pred_classes_rf <- predict(fit_rf, newdata=df_test)
cm_rf <- confusionMatrix(data = pred_classes_rf,
reference = df_test$stroke,
mode="everything",
positive="yes")
cm_rf
library(doParallel)
cl <- makePSOCKcluster(18)
registerDoParallel(cl)
set.seed(123)
fit_rf <- train(stroke ~ .,
data = df_train_smote,
metric = "Kappa",
method = "rf",
trControl = fit_ctrl_sens,
tuneGrid = expand.grid(.mtry = seq(3, 6, 0.5)), # I've tried all values greater than these
verbosity = 0,
verbose = FALSE)
stopCluster(cl)
fit_rf
pred_classes_rf <- predict(fit_rf, newdata=df_test)
cm_rf <- confusionMatrix(data = pred_classes_rf,
reference = df_test$stroke,
mode="everything",
positive="yes")
cm_rf
library(doParallel)
cl <- makePSOCKcluster(18)
registerDoParallel(cl)
set.seed(123)
fit_rf <- train(stroke ~ .,
data = df_train_smote,
metric = "Kappa",
method = "rf",
trControl = fit_ctrl_sens,
tuneGrid = expand.grid(.mtry = seq(2, 6, 0.5)), # I've tried all values greater than these
verbosity = 0,
verbose = FALSE)
stopCluster(cl)
fit_rf
imp_vars_rf <- varImp(fit_rf)
plot(imp_vars_rf, main="Variable Importance with RF")
# calculate ROC
perf_pred <- get_roc(fit_rf, df_test)
perf_rf <- perf_pred[[1]]
pred_rf <- perf_pred[[2]]
# take AUC
auc_rf <- round(unlist(slot(performance(pred_rf, measure = "auc"), "y.values")), 3)
# plot
plot(perf_rf, main = "RF ROC curve", col = "steelblue", lwd = 3)
abline(a = 0, b = 1, lwd = 3, lty = 2, col = 1)
legend(x = 0.7, y = 0.3, legend = paste0("AUC = ", auc_rf))
library(doParallel)
cl <- makePSOCKcluster(18)
registerDoParallel(cl)
set.seed(123)
fit_rf <- train(stroke ~ .,
data = df_train_smote,
metric = "Sens",
method = "rf",
trControl = fit_ctrl_sens,
tuneGrid = expand.grid(.mtry = seq(2, 6, 0.5)), # I've tried all values greater than these
verbosity = 0,
verbose = FALSE)
stopCluster(cl)
fit_rf
?trainControl
pred_classes_rf
?prediction
?predict
?predict.train
predict(fit_rf, newdata=df_test, type="prob")
pred_prob_rf <- predict(fit_rf, newdata=df_test, type = "prob")
pred_prob_rf
pred_prob_rf$yes
pred_prob_rf <- predict(fit_rf, newdata=df_test, type = "prob")
# turn probs into classes
pred_class_cutoff_rf <- map_chr(pred_prob_rf$yes, function(x){
if (x >= 0.7){
return("yes")}
else {
return("no")
}})
cm_cutoff_rf <- confusionMatrix(data = pred_class_cutoff_rf,
reference = df_test$stroke,
mode="everything",
positive="yes")
pred_class_cutoff_rf <- as.factor(pred_class_cutoff_rf)
cm_cutoff_rf <- confusionMatrix(data = pred_class_cutoff_rf,
reference = df_test$stroke,
mode="everything",
positive="yes")
cm_cutoff_rf
pred_prob_rf <- predict(fit_rf, newdata=df_test, type = "prob")
# turn probs into classes
pred_class_cutoff_rf <- map_chr(pred_prob_rf$yes, function(x){
if (x >= 0.3){
return("yes")}
else {
return("no")
}})
pred_class_cutoff_rf <- as.factor(pred_class_cutoff_rf)
cm_cutoff_rf <- confusionMatrix(data = pred_class_cutoff_rf,
reference = df_test$stroke,
mode="everything",
positive="yes")
cm_cutoff_rf
pred_prob_rf <- predict(fit_rf, newdata=df_test, type = "prob")
# turn probs into classes
pred_class_cutoff_rf <- map_chr(pred_prob_rf$yes, function(x){
if (x >= 0.1){
return("yes")}
else {
return("no")
}})
pred_class_cutoff_rf <- as.factor(pred_class_cutoff_rf)
cm_cutoff_rf <- confusionMatrix(data = pred_class_cutoff_rf,
reference = df_test$stroke,
mode="everything",
positive="yes")
cm_cutoff_rf
save.image("data/workspace.RData")
load("data/workspace.RData")
library(tidyverse)
ifelse(pred_prob_rf$yes > cutoff, "yes", "no")
ifelse(pred_prob_rf$yes > o.1, "yes", "no")
ifelse(pred_prob_rf$yes > 0.1, "yes", "no")
knitr::opts_chunk$set(echo = TRUE, message = F, warning = F, cache = F)
library(tidyverse)
library(caret)
#library(GGally)
library(DMwR) # installed via archive: install.packages("/Path/to/DMwR_0.4.1.tar.gz", repos=NULL, type="source" )
library(ROCR)
# calculate ROC
perf_pred <- get_roc(fit_rf, df_test)
perf_rf <- perf_pred[[1]]
pred_rf <- perf_pred[[2]]
# take AUC
auc_rf <- round(unlist(slot(performance(pred_rf, measure = "auc"), "y.values")), 3)
# plot
plot(perf_rf, main = "RF ROC curve", col = "steelblue", lwd = 3)
abline(a = 0, b = 1, lwd = 3, lty = 2, col = 1)
legend(x = 0.7, y = 0.3, legend = paste0("AUC = ", auc_rf))
head(pred_prob_rf)
?performance
performance(pred_rf, measure = "tpr", x.measure = "cutoff")
pot(performance(pred_rf, measure = "tpr", x.measure = "cutoff"))
plot(performance(pred_rf, measure = "tpr", x.measure = "cutoff"))
plot(performance(pred_rf, measure = "fpr", x.measure = "cutoff"))
?plot
# use pred_rf (pred_roc) object
plot(performance(pred_rf, measure = "tpr", x.measure = "cutoff"))
plot(performance(pred_rf, measure = "fpr", x.measure = "cutoff"))
# use pred_rf (pred_roc) object
plot(performance(pred_rf, measure = "tpr", x.measure = "cutoff"))
plot(performance(pred_rf, measure = "fpr", x.measure = "cutoff"))
# use pred_rf (pred_roc) object
plot(performance(pred_rf, measure = "tpr", x.measure = "cutoff"), col="steelblue")
plot(performance(pred_rf, measure = "fpr", x.measure = "cutoff"), add = T, col = "red")
# use pred_rf (pred_roc) object
plot(performance(pred_rf, measure = "tpr", x.measure = "cutoff"), col="steelblue")
plot(performance(pred_rf, measure = "fpr", x.measure = "cutoff"), add = T, col = "red")
legend(x = 0.7,y = 0.7, c("TPR (Recall)", "FPR (1-Spec)"),
lty = 1, col =c('steelblue', 'red'), bty = 'n', cex = 1, lwd = 2)
# use pred_rf (pred_roc) object
plot(performance(pred_rf, measure = "tpr", x.measure = "cutoff"), col="steelblue", x = "Rate")
# use pred_rf (pred_roc) object
plot(performance(pred_rf, measure = "tpr", x.measure = "cutoff"), col="steelblue", xlab = "Rate")
plot(performance(pred_rf, measure = "fpr", x.measure = "cutoff"), add = T, col = "red")
legend(x = 0.7,y = 0.7, c("TPR (Recall)", "FPR (1-Spec)"),
lty = 1, col =c('steelblue', 'red'), bty = 'n', cex = 1, lwd = 2)
# use pred_rf (pred_roc) object
plot(performance(pred_rf, measure = "tpr", x.measure = "cutoff"), col="steelblue", ylab = "Rate")
plot(performance(pred_rf, measure = "fpr", x.measure = "cutoff"), add = T, col = "red")
legend(x = 0.7,y = 0.7, c("TPR (Recall)", "FPR (1-Spec)"),
lty = 1, col =c('steelblue', 'red'), bty = 'n', cex = 1, lwd = 2)
# use pred_rf (pred_roc) object
plot(performance(pred_rf, measure = "tpr", x.measure = "cutoff"), col="steelblue", ylab = "Rate", xlab="Probability cut-off")
plot(performance(pred_rf, measure = "fpr", x.measure = "cutoff"), add = T, col = "red")
legend(x = 0.7,y = 0.7, c("TPR (Recall)", "FPR (1-Spec)"),
lty = 1, col =c('steelblue', 'red'), bty = 'n', cex = 1, lwd = 2)
# use pred_rf (pred_roc) object
plot(performance(pred_rf, measure = "tpr", x.measure = "cutoff"), col="steelblue", ylab = "Rate", xlab="Probability cutoff")
plot(performance(pred_rf, measure = "fpr", x.measure = "cutoff"), add = T, col = "red")
legend(x = 0.7,y = 0.7, c("TPR (Recall)", "FPR (1-Spec)"),
lty = 1, col =c('steelblue', 'red'), bty = 'n', cex = 1, lwd = 2)
abline(v= 0.1, lwd = 2, lty=6)
# use pred_rf (pred_roc) object
plot(performance(pred_rf, measure = "tpr", x.measure = "cutoff"), col="steelblue", ylab = "Rate", xlab="Probability cutoff")
plot(performance(pred_rf, measure = "fpr", x.measure = "cutoff"), add = T, col = "red")
legend(x = 0.7,y = 0.7, c("TPR (Recall)", "FPR (1-Spec)"),
lty = 1, col =c('steelblue', 'red'), bty = 'n', cex = 1, lwd = 2)
abline(v= 0.08, lwd = 2, lty=6)
# use pred_rf (pred_roc) object
plot(performance(pred_rf, measure = "tpr", x.measure = "cutoff"), col="steelblue", ylab = "Rate", xlab="Probability cutoff")
plot(performance(pred_rf, measure = "fpr", x.measure = "cutoff"), add = T, col = "red")
legend(x = 0.7,y = 0.7, c("TPR (Recall)", "FPR (1-Spec)"),
lty = 1, col =c('steelblue', 'red'), bty = 'n', cex = 1, lwd = 2)
abline(v= 0.07, lwd = 2, lty=6)
# predict probabilities
pred_prob_rf <- predict(fit_rf, newdata=df_test, type = "prob")
# choose your cut-off
cutoff = 0.05
# turn probabilities into classes
pred_class_rf <- ifelse(pred_prob_rf$yes > cutoff, "yes", "no")
pred_class_cutoff_rf <- as.factor(pred_class_cutoff_rf)
cm_cutoff_rf <- confusionMatrix(data = pred_class_cutoff_rf,
reference = df_test$stroke,
mode="everything",
positive="yes")
cm_cutoff_rf
# predict probabilities
pred_prob_rf <- predict(fit_rf, newdata=df_test, type = "prob")
# choose your cut-off
cutoff = 0.01
# turn probabilities into classes
pred_class_rf <- ifelse(pred_prob_rf$yes > cutoff, "yes", "no")
pred_class_cutoff_rf <- as.factor(pred_class_cutoff_rf)
cm_cutoff_rf <- confusionMatrix(data = pred_class_cutoff_rf,
reference = df_test$stroke,
mode="everything",
positive="yes")
cm_cutoff_rf
# predict probabilities
pred_prob_rf <- predict(fit_rf, newdata=df_test, type = "prob")
# choose your cut-off
cutoff = 0.00
# turn probabilities into classes
pred_class_rf <- ifelse(pred_prob_rf$yes > cutoff, "yes", "no")
pred_class_cutoff_rf <- as.factor(pred_class_cutoff_rf)
cm_cutoff_rf <- confusionMatrix(data = pred_class_cutoff_rf,
reference = df_test$stroke,
mode="everything",
positive="yes")
cm_cutoff_rf
# predict probabilities
pred_prob_rf <- predict(fit_rf, newdata=df_test, type = "prob")
# choose your cut-off
cutoff = 0.06
# turn probabilities into classes
pred_class_rf <- ifelse(pred_prob_rf$yes > cutoff, "yes", "no")
pred_class_cutoff_rf <- as.factor(pred_class_cutoff_rf)
cm_cutoff_rf <- confusionMatrix(data = pred_class_cutoff_rf,
reference = df_test$stroke,
mode="everything",
positive="yes")
cm_cutoff_rf
# use pred_rf (pred_roc) object
plot(performance(pred_rf, measure = "tpr", x.measure = "cutoff"),
col="steelblue",
ylab = "Rate",
xlab="Probability cutoff")
plot(performance(pred_rf, measure = "fpr", x.measure = "cutoff"),
add = T, col = "red")
legend(x = 0.7,y = 0.7, c("TPR (Recall)", "FPR (1-Spec)"),
lty = 1, col =c('steelblue', 'red'), bty = 'n', cex = 1, lwd = 2)
abline(v= 0.07, lwd = 2, lty=6)
# predict probabilities
pred_prob_rf <- predict(fit_rf, newdata=df_test, type = "prob")
# choose your cut-off
cutoff = 0.06
# turn probabilities into classes
pred_class_rf <- ifelse(pred_prob_rf$yes > cutoff, "yes", "no")
pred_class_rf <- as.factor(pred_class_rf)
cm_rf <- confusionMatrix(data = pred_class_rf,
reference = df_test$stroke,
mode="everything",
positive="yes")
cm_rf
# predict probabilities
pred_prob_rf <- predict(fit_rf, newdata=df_test, type = "prob")
# choose your cut-off
cutoff = 0.1
# turn probabilities into classes
pred_class_rf <- ifelse(pred_prob_rf$yes > cutoff, "yes", "no")
pred_class_rf <- as.factor(pred_class_rf)
cm_rf <- confusionMatrix(data = pred_class_rf,
reference = df_test$stroke,
mode="everything",
positive="yes")
cm_rf
# predict probabilities
pred_prob_rf <- predict(fit_rf, newdata=df_test, type = "prob")
# choose your cut-off
cutoff = 0.07
# turn probabilities into classes
pred_class_rf <- ifelse(pred_prob_rf$yes > cutoff, "yes", "no")
pred_class_rf <- as.factor(pred_class_rf)
cm_rf <- confusionMatrix(data = pred_class_rf,
reference = df_test$stroke,
mode="everything",
positive="yes")
cm_rf
# predict probabilities
pred_prob_rf <- predict(fit_rf, newdata=df_test, type = "prob")
# choose your cut-off
cutoff = 0.06
# turn probabilities into classes
pred_class_rf <- ifelse(pred_prob_rf$yes > cutoff, "yes", "no")
pred_class_rf <- as.factor(pred_class_rf)
cm_rf <- confusionMatrix(data = pred_class_rf,
reference = df_test$stroke,
mode="everything",
positive="yes")
cm_rf
